{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-gLx418VYL2"
      },
      "source": [
        "## Chat Models - Output Parsing\n",
        "\n",
        "Language models output text. But many times you may want to get more structured information than just text back. This is where output parsers come in.\n",
        "\n",
        "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
        "\n",
        "\"Get format instructions\": A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
        "\"Parse\": A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.\n",
        "And then one optional one:\n",
        "\n",
        "\"Parse with prompt\": A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v2ilqnwVYL4"
      },
      "outputs": [],
      "source": [
        "%pip install langchain langchain_openai langchain-community --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPEwTA-KVYL4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = 'API_KEY_HERE'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K36LL85fVYL4"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uWdT-PjVYL5"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAh-_Jg1VYL5"
      },
      "outputs": [],
      "source": [
        "class Joke(BaseModel):\n",
        "    setup: str = Field(description=\"The setup to the joke\")\n",
        "    punchline: str = Field(description=\"The punchline to the joke\")\n",
        "\n",
        "class Jokes(BaseModel):\n",
        "    jokes: List[Joke] = Field(description=\"A list of jokes\")\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Joke)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXPfPpXfVYL5"
      },
      "outputs": [],
      "source": [
        "template = \"Answer the user query.\\n{format_instructions}\\n{query}\"\n",
        "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
        "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt])\n",
        "\n",
        "\n",
        "messages = chat_prompt.invoke({\n",
        "    \"query\": \"What is a really funny joke about Python programming?\",\n",
        "    \"format_instructions\": parser.get_format_instructions()\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3UZKhVNVYL5"
      },
      "outputs": [],
      "source": [
        "result = model.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmN6XukPVYL6",
        "outputId": "3fd9e474-9244-4bb0-b63b-94400ff7f243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Why do Python programmers prefer dark mode?\n",
            "Because light attracts bugs!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    joke_object = parser.parse(result.content)\n",
        "    print(joke_object.setup)\n",
        "    print(joke_object.punchline)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsoqBpvsVYL6"
      },
      "outputs": [],
      "source": [
        "structured_llm = model.with_structured_output(Joke)\n",
        "result = structured_llm.invoke(\"What is a really funny joke about Python programming?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgVbQhH-VYL6",
        "outputId": "bcd70790-b5ab-4f12-bbb8-b600f44fadfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Because light attracts bugs!\n",
            "<class '__main__.Joke'>\n"
          ]
        }
      ],
      "source": [
        "print(result.punchline)\n",
        "print(type(result))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}