{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: anthropic in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (0.19.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (1.3.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anthropic) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (3.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.5.0->anthropic) (1.1.0)\n",
      "Requirement already satisfied: certifi in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->anthropic) (2021.10.8)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from httpx<1,>=0.23.0->anthropic) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from pydantic<3,>=1.9.0->anthropic) (2.16.2)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from tokenizers>=0.13.0->anthropic) (0.20.3)\n",
      "Requirement already satisfied: filelock in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2023.12.2)\n",
      "Requirement already satisfied: requests in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (23.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/michaeltaylor/Library/Python/3.9/lib/python/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.12)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Description</th>\n",
       "      <th>Published</th>\n",
       "      <th>Author</th>\n",
       "      <th>Hearts</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How Duolingo reignited user growth</td>\n",
       "      <td>https://www.lennysnewsletter.com/p/how-duoling...</td>\n",
       "      <td>The story behind Duolingo's 350% growth accele...</td>\n",
       "      <td>Feb 28, 2023</td>\n",
       "      <td>JORGE MAZAL</td>\n",
       "      <td>673.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How the biggest consumer apps got their first ...</td>\n",
       "      <td>https://www.lennysnewsletter.com/p/how-the-big...</td>\n",
       "      <td>Considering every startup confronts this quest...</td>\n",
       "      <td>May 12, 2020</td>\n",
       "      <td>LENNY RACHITSKY</td>\n",
       "      <td>452.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You should be playing with GPTs at work</td>\n",
       "      <td>https://www.lennysnewsletter.com/p/you-should-...</td>\n",
       "      <td>20 examples of how people are using custom GPT...</td>\n",
       "      <td>Feb 20</td>\n",
       "      <td>LENNY RACHITSKY</td>\n",
       "      <td>354.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to use ChatGPT in your PM work</td>\n",
       "      <td>https://www.lennysnewsletter.com/p/how-to-use-...</td>\n",
       "      <td>Real-life examples (and actual prompts) of how...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>â€¢</td>\n",
       "      <td>362.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 10 commandments of salary negotiation</td>\n",
       "      <td>https://www.lennysnewsletter.com/p/negotiating...</td>\n",
       "      <td>Guest post by Niya Dragova, co-founder of Candor</td>\n",
       "      <td>Sep 24, 2021</td>\n",
       "      <td>LENNY RACHITSKY</td>\n",
       "      <td>157.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                 How Duolingo reignited user growth   \n",
       "1  How the biggest consumer apps got their first ...   \n",
       "2            You should be playing with GPTs at work   \n",
       "3                 How to use ChatGPT in your PM work   \n",
       "4          The 10 commandments of salary negotiation   \n",
       "\n",
       "                                                Link  \\\n",
       "0  https://www.lennysnewsletter.com/p/how-duoling...   \n",
       "1  https://www.lennysnewsletter.com/p/how-the-big...   \n",
       "2  https://www.lennysnewsletter.com/p/you-should-...   \n",
       "3  https://www.lennysnewsletter.com/p/how-to-use-...   \n",
       "4  https://www.lennysnewsletter.com/p/negotiating...   \n",
       "\n",
       "                                         Description     Published  \\\n",
       "0  The story behind Duolingo's 350% growth accele...  Feb 28, 2023   \n",
       "1  Considering every startup confronts this quest...  May 12, 2020   \n",
       "2  20 examples of how people are using custom GPT...        Feb 20   \n",
       "3  Real-life examples (and actual prompts) of how...           NaN   \n",
       "4   Guest post by Niya Dragova, co-founder of Candor  Sep 24, 2021   \n",
       "\n",
       "            Author  Hearts  Comments  \n",
       "0      JORGE MAZAL   673.0      59.0  \n",
       "1  LENNY RACHITSKY   452.0      29.0  \n",
       "2  LENNY RACHITSKY   354.0      21.0  \n",
       "3                â€¢   362.0       1.0  \n",
       "4  LENNY RACHITSKY   157.0      53.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import Lenny Newsletter - Sheet1.csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"Lenny Newsletter - Sheet1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('How Duolingo reignited user growth', 'https://www.lennysnewsletter.com/p/how-duolingo-reignited-user-growth'), ('How the biggest consumer apps got their first 1,000 users', 'https://www.lennysnewsletter.com/p/how-the-biggest-consumer-apps-got'), ('You should be playing with GPTs at work', 'https://www.lennysnewsletter.com/p/you-should-be-playing-with-gpts-at'), ('How to use ChatGPT in your PM work', 'https://www.lennysnewsletter.com/p/how-to-use-chatgpt-in-your-pm-work'), ('The 10 commandments of salary negotiation', 'https://www.lennysnewsletter.com/p/negotiating-comp')]\n"
     ]
    }
   ],
   "source": [
    "# urls = list of \"Title\" and \"Link\" as a list of tuples\n",
    "urls = list(zip(df[\"Title\"], df[\"Link\"]))\n",
    "\n",
    "print(urls[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from anthropic import Anthropic\n",
    "import os\n",
    "\n",
    "client = Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"Hello\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('How Duolingo reignited user growth', 'https://www.lennysnewsletter.com/p/how-duolingo-reignited-user-growth')\n",
      "One nonobvious insight is that borrowing successful features from other products requires carefully adapting them to your specific context. As the author notes, \"We had borrowed successful features from other products, but the wrong way. We had failed to account for how a change in context can impact the success of a feature.\"\n",
      "\n",
      "\n",
      "('How the biggest consumer apps got their first 1,000 users', 'https://www.lennysnewsletter.com/p/how-the-biggest-consumer-apps-got')\n",
      "One nonobvious insight is that most successful consumer apps found their early users from just a single strategy, rather than employing many different tactics. \"Most startups found their early users from just a single strategy. A few like Product Hunt and Pinterest found success using a handful. No one found success from more than three.\"\n",
      "\n",
      "\n",
      "('You should be playing with GPTs at work', 'https://www.lennysnewsletter.com/p/you-should-be-playing-with-gpts-at')\n",
      "One nonobvious insight is that custom GPTs can significantly boost productivity for non-engineering teams. The author shares an example where \"GPT revolutionizes sales\" by \"summarizing customer interviews\" to \"identify recurring pain points,\" \"find compelling customer testimonials,\" and \"generate action items.\" This shows how GPTs can automate time-consuming tasks for sales and marketing teams, not just engineers.\n",
      "\n",
      "\n",
      "('How to use ChatGPT in your PM work', 'https://www.lennysnewsletter.com/p/how-to-use-chatgpt-in-your-pm-work')\n",
      "One nonobvious insight is that ChatGPT can help PMs \"Identify gaps and hidden assumptions\" in their thinking by asking questions like \"What am I missing here?\" or \"What am I being overly optimistic about?\" This allows PMs to uncover blind spots and strengthen their arguments.\n",
      "\n",
      "\n",
      "('The 10 commandments of salary negotiation', 'https://www.lennysnewsletter.com/p/negotiating-comp')\n",
      "One nonobvious insight is that at large tech companies like FAANG, the recruiter may have little control over the compensation offer, which is instead set by a separate \"compensation committee.\" As the author states: \"At FAANG-size companies (i.e. over 5K employees), compensation is heavily formulaic... The recruiter then gives you the number, and every time you negotiate they have to go back to that committee to ask for a re-evaluation.\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# loop through the files in the folder and summarize each\n",
    "summaries = {}\n",
    "\n",
    "# get a list of urls\n",
    "for url in urls[:5]:\n",
    "    with open(f\"lenny/{url[1].split('/')[-1]}.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-3-opus-20240229\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": f\"<text>{text}</text>\\nPull out one nonobvious insight from this text. Use quotes where relevant. Be extremely concise\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    summaries[url] = message.content[0].text\n",
    "\n",
    "# print the summaries\n",
    "for url, summary in summaries.items():\n",
    "    print(url)\n",
    "    print(summary)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185426.25\n"
     ]
    }
   ],
   "source": [
    "#loop through the files in the folder and add all the text together in one file, separated by a divider ------------\n",
    "all_text = \"\"\n",
    "for url in urls[:50]:\n",
    "    with open(f\"lenny/{url[1].split('/')[-1]}.txt\", \"r\") as file:\n",
    "        text = file.read()\n",
    "        all_text += \"<article>\" + text + \"</article>\\n------------------------------------\\n\"\n",
    "\n",
    "# how many tokens based on length of the text. 1 token is 4 characters\n",
    "print(len(all_text) / 4)\n",
    "\n",
    "with open(\"lenny/all_text.txt\", \"w\") as file:\n",
    "    file.write(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I analyzed the 40 articles from Lenny's Newsletter that you provided. Here is a summary of my findings:\n",
      "\n",
      "Content Summary:\n",
      "The articles cover a wide range of topics related to product management, growth, career development, and entrepreneurship. Common themes include:\n",
      "\n",
      "- Tactical advice and frameworks for product development, prioritization, strategy, pricing, and growth \n",
      "- Inside stories of how top companies like Netflix, Figma, Notion, Shopify, and Duolingo build and grow products\n",
      "- Interviews with experienced leaders sharing career lessons, productivity tips, and insights on leadership\n",
      "- Guidance for early-stage startups on ideation, validation, finding product-market fit, and scaling\n",
      "- Personal stories of career journeys, lessons learned from failure, and principles for success\n",
      "\n",
      "The content is highly practical, example-driven, and grounded in the real-world experience of the author Lenny Rachitsky and the many experts he interviews and features. The articles go deep on specific topics and aim to be the definitive guide on the subject.\n",
      "\n",
      "Word Choice and Style:\n",
      "The writing style is conversational, direct and easy to follow, even when covering complex topics. Some notable characteristics of the writing:\n",
      "\n",
      "- Frequent use of the 2nd person \"you\" to speak directly to the reader\n",
      "- Liberal use of bulleted and numbered lists to organize information \n",
      "- Bolding of key phrases and takeaways to make skimmable\n",
      "- Relatively simple vocabulary and short paragraphs\n",
      "- Sparing use of jargon, always defined, in favor of plain language\n",
      "- Metaphors and analogies to make concepts relatable (e.g. describing a business as an equation)\n",
      "- Light-hearted asides and bits of humor sprinkled in\n",
      "\n",
      "The writing is more casual and bloggy in style compared to traditional business writing. It reads like a knowledgeable friend sharing advice rather than an academic journal. \n",
      "\n",
      "Estimated Reading Level: \n",
      "Based on the vocabulary and sentence structure, I'd estimate the reading level to be around 8th grade on the Fleschâ€“Kincaid readability index. The articles should be easily understood by the average adult reader.\n",
      "\n",
      "Patterns and Insights:\n",
      "Some non-obvious patterns I noticed:\n",
      "\n",
      "- Lenny's own writing accounts for less than half the articles. Most are contributed by guest experts or interviews.\n",
      "\n",
      "- There are many compendium-style posts (e.g. \"best of\" lists, mega-threads of examples). This makes the newsletter a go-to reference.\n",
      "\n",
      "- Failure stories are featured almost as much as success stories. The newsletter doesn't shy away from harsh realities.\n",
      "\n",
      "- The growth articles focus more on organic, product-led growth over paid acquisition. Very little mention of ads.\n",
      "\n",
      "- Design is rarely mentioned directly. The product advice is more PM-centric than design-centric.\n",
      "\n",
      "- Analytics and metrics are a frequent focus area, especially in the growth-related articles. Measurement is key.\n",
      "\n",
      "- The career advice has a slight bias toward hyper-growth, VC-backed tech startups over lifestyle businesses.\n",
      "\n",
      "Overall, Lenny's Newsletter provides in-depth, hands-on startup/tech product and growth advice with an emphasis on practitioner experience over theory. The prolific output and depth of expertise portrayed establish strong thought leadership in the space. The accessible writing style makes it an appealing resource for a broad professional audience.\n"
     ]
    }
   ],
   "source": [
    "# summarize the combined text\n",
    "with open(\"lenny/all_text.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"{text}\\nSummarize these articles, analyze the word choice, identify any patterns, estimate the reading level, and tell me any other non obvious insights about this publication.\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the templates I found based on analyzing the given titles:\n",
      "\n",
      "Template: \"How X Does Y\"\n",
      "Description: The title explains how a specific company or product (X) accomplishes a certain goal or process (Y).\n",
      "Examples:\n",
      "- How Duolingo reignited user growth\n",
      "- How Linear builds product\n",
      "- How Shopify builds product\n",
      "\n",
      "Template: \"How to X\"\n",
      "Description: The title provides instructions or advice on how to achieve a specific outcome (X).\n",
      "Examples:\n",
      "- How to use ChatGPT in your PM work\n",
      "- How to validate your B2B startup idea\n",
      "- How to pass any first-round interview (even in a terrible talent market)\n",
      "\n",
      "Template: \"The X of Y\" / \"The X Y\"\n",
      "Description: The first word (X) is an adjective or noun describing an important aspect, quality, or guide related to the main topic (Y).\n",
      "Examples:\n",
      "- The 10 commandments of salary negotiation\n",
      "- The ultimate guide to willingness-to-pay\n",
      "- The unconventional Palantir principles that catalyzed a generation of startups\n",
      "\n",
      "Template: \"X for Y\"\n",
      "Description: The title indicates that the content provides something (X) to help with a specific topic or goal (Y).\n",
      "Examples:\n",
      "- A guide for finding product-market fit in B2B\n",
      "- Inspiration for the year ahead\n",
      "- Examples and templates of 1-Pagers and PRDs\n",
      "\n",
      "Template: \"X + Number\"\n",
      "Description: The title includes a number to quantify something related to the main topic (X).\n",
      "Examples:\n",
      "- 500,000\n",
      "- 60 ideas to boost your growth\n",
      "- 28 Ways to Grow Supply in a Marketplace ðŸ“ˆ\n",
      "\n",
      "Template: \"X | Person Name\"\n",
      "Description: The title mentions the main topic (X) and the name of a person who likely authored the content or is a subject matter expert.\n",
      "Examples:\n",
      "- Good Strategy, Bad Strategy | Richard Rumelt\n",
      "- Making time for what matters | Jake Knapp and John Zeratsky (authors of Sprint and Make Time, co-founders of Character Capital)\n",
      "- Strategies for becoming less distracted and improving focus | Nir Eyal (author of Indistractable and Hooked)\n"
     ]
    }
   ],
   "source": [
    "titles = \"\\n\".join(df[\"Title\"].tolist())\n",
    "\n",
    "prompt_template = f\"\"\"Successful titles follow templates. Here are examples of templates:\n",
    "\n",
    "Template: \"The Blank of Blank\"\n",
    "Description: The format is where the first blank is a word not usually associated with the topic, and the second blank is the topic of the content.\n",
    "Example 1 - The War of Art\n",
    "Example 2 - The Psychology of Money\n",
    "Example 3 - The Subtle Art of Not Giving a Fuck\n",
    "\n",
    "Template: \"Odd Topic\"\n",
    "Description: The first word is an odd adjective to pair with the topic of the content, and the second word is the topic of the content.\n",
    "Example 1 - Atomic Habits\n",
    "Example 2 - Extreme Ownership\n",
    "Example 3 - Deep Work\n",
    "\n",
    "Template: \"The Definitive Guide\"\n",
    "Description: The first word is an unusual adjective not normally associated with the topic of the content, and the second word is the topic of the content.\n",
    "Example 1 - WebAssembly: The Definitive Guide\n",
    "Example 2 - Cassandra: The Definitive Guide\n",
    "Example 3 - Kafka: The Definitive Guide, 2nd Edition\n",
    "\n",
    "Categorize the following titles into templates. Make up new templates based on what you find. Titles can be assigned to multiple templates. Only list a maximum of 3 examples of titles that fit each template, but skip the template if there are not at least 2 examples. Ignore edition numbers or versions in your analysis. Do not fit a title to a template if it doesn't apply. The example templates may not be suitable for these titles.\n",
    "\n",
    "Titles:\n",
    "{ titles }\n",
    "\"\"\"\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=\"claude-3-opus-20240229\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt_template\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
