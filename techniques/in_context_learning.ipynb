{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In Context Learning\n",
    "\n",
    "In-Context Learning (ICL) in prompt engineering refers to the ability of large language models to adapt and perform tasks based on examples provided within the prompt itself, without requiring fine-tuning or additional training. This technique leverages the model's existing knowledge and pattern recognition capabilities to understand and emulate the desired behavior or output format. \n",
    "\n",
    "By including relevant examples or demonstrations directly in the prompt (referred to as 'Few-Shot' prompting), users can guide the model to produce more accurate and contextually appropriate responses for specific tasks. ICL allows for quick adaptation to new tasks or domains, making it a powerful and flexible approach in prompt engineering for enhancing model performance across various applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Models are Few-Shot Learners\n",
    "\n",
    "This paper, which introduced GPT-3 (Generative Pre-trained Transformer 3), demonstrated the remarkable ability of large language models to perform various tasks with minimal task-specific examples provided in the prompt.\n",
    "The authors showed that GPT-3 could adapt to new tasks simply by presenting it with a few examples in the input prompt, without any gradient updates or fine-tuning, leading to double-digit improvements in accuracy.\n",
    "\n",
    "This emergent capability, which they termed \"in-context learning,\" marked a significant advancement in the field of natural language processing and prompt engineering. It's worth noting that while this paper brought widespread attention to the concept, it builds upon earlier work in transfer learning and meta-learning. However, the scale and effectiveness demonstrated in the GPT-3 paper made it a landmark study in the field of prompt engineering and large language models.\n",
    "\n",
    "> [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) by Brown, T., et al. (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product description: A shoe that fits any foot size\n",
      "Product names: InfiniteFit, UniversalStride, OmniFitBonanza\n"
     ]
    }
   ],
   "source": [
    "# Zero-shot prompting provides no examples\n",
    "\n",
    "prompt_zero_shot = \"\"\"Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs.\n",
    "\n",
    "Return the results as a comma separated list, in this format:\n",
    "Product description: A shoe that fits any foot size\n",
    "Product names: [list of 3 product names]\"\"\"\n",
    "\n",
    "# call openai with this prompt\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_zero_shot}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs.\n",
      "\n",
      "Return the results as a comma separated list, in this format:\n",
      "Product description: A shoe that fits any foot size\n",
      "Product names: [list of 3 product names]\n",
      "\n",
      "## Examples\n",
      "Product description: A refrigerator that dispenses beer\n",
      "Product names: iBarFridge, iFridgeBeer, iDrinkBeerFridge\n",
      "\n",
      "Product description: A watch that can tell accurate time in space\n",
      "Product names: iNaut, iSpace, iTime\n",
      "\n",
      "Product description: A home milkshake maker\n",
      "Product names: iShake, iSmoothie, iShake Mini\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Few-shot prompting provides 1-5 examples\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"description\": \"A refrigerator that dispenses beer\",\n",
    "        \"names\": \"iBarFridge, iFridgeBeer, iDrinkBeerFridge\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A watch that can tell accurate time in space\",\n",
    "        \"names\": \"iNaut, iSpace, iTime\"\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"A home milkshake maker\",\n",
    "        \"names\": \"iShake, iSmoothie, iShake Mini\"\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt_few_shot = prompt_zero_shot + \"\\n\\n## Examples\"\n",
    "\n",
    "for example in examples:\n",
    "    prompt_few_shot += f\"\\nProduct description: {example['description']}\\n\"\n",
    "    prompt_few_shot += f\"Product names: {example['names']}\\n\"\n",
    "\n",
    "print(prompt_few_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product description: A shoe that fits any foot size\n",
      "Product names: iFitShoe, iStepTech, iStrideFlexible\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_few_shot}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: 66.66666666666666\n",
      "'iShoe' starts with 'i': True\n",
      "'FitAll' starts with 'i': False\n",
      "'iSize' starts with 'i': True\n"
     ]
    }
   ],
   "source": [
    "def eval_names_start_with_i(response):\n",
    "    \"\"\"\n",
    "    Evaluates the percentage of product names in the response that start with 'i'.\n",
    "    \n",
    "    Args:\n",
    "    response (str): The full response string from the API.\n",
    "    \n",
    "    Returns:\n",
    "    float: The percentage of names that start with 'i' (case-insensitive).\n",
    "    \"\"\"\n",
    "    # Split the response to get the product names part\n",
    "    product_names_part = response.split(\"Product names:\")[-1].strip()\n",
    "    \n",
    "    # Remove brackets and split names by comma\n",
    "    names = [name.strip() for name in product_names_part.strip(\"[]\").split(\",\")]\n",
    "    \n",
    "    # Count names starting with 'i' and calculate percentage\n",
    "    i_count = sum(name.lower().startswith('i') for name in names)\n",
    "    total_names = len(names)\n",
    "    \n",
    "    # Return the percentage (avoid division by zero)\n",
    "    return (i_count / total_names * 100) if total_names > 0 else 0\n",
    "\n",
    "# Test the function with a sample response\n",
    "sample_response = \"\"\"Product description: A shoe that fits any foot size\n",
    "Product names: iShoe, FitAll, iSize\"\"\"\n",
    "\n",
    "results = eval_names_start_with_i(sample_response)\n",
    "print(\"Evaluation results:\", results)\n",
    "\n",
    "# Print individual results\n",
    "for name in sample_response.split(\"Product names:\")[-1].strip(\"[]\").split(\",\"):\n",
    "    result = name.strip().lower().startswith('i')\n",
    "    print(f\"'{name.strip()}' starts with 'i': {result}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Zero-shot prompt:\n",
      "---\n",
      "Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs.\n",
      "\n",
      "Return the results as a comma separated list, in this format:\n",
      "Product description: A shoe that fits any foot size\n",
      "Product names: [list of 3 product names] \n",
      "\n",
      "---\n",
      "One-shot prompt:\n",
      "---\n",
      "Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs.\n",
      "\n",
      "Return the results as a comma separated list, in this format:\n",
      "Product description: A shoe that fits any foot size\n",
      "Product names: [list of 3 product names]\n",
      "\n",
      "## Example\n",
      "Product description: A refrigerator that dispenses beer\n",
      "Product names: iBarFridge, iFridgeBeer, iDrinkBeerFridge\n",
      " \n",
      "\n",
      "---\n",
      "Two-shot prompt:\n",
      "---\n",
      "Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs.\n",
      "\n",
      "Return the results as a comma separated list, in this format:\n",
      "Product description: A shoe that fits any foot size\n",
      "Product names: [list of 3 product names]\n",
      "\n",
      "## Example\n",
      "Product description: A refrigerator that dispenses beer\n",
      "Product names: iBarFridge, iFridgeBeer, iDrinkBeerFridge\n",
      "\n",
      "Product description: A watch that can tell accurate time in space\n",
      "Product names: iNaut, iSpace, iTime\n",
      " \n",
      "\n",
      "---\n",
      "Three-shot prompt:\n",
      "---\n",
      "Brainstorm a list of product names for a shoe that fits any foot size, in the style of Steve Jobs.\n",
      "\n",
      "Return the results as a comma separated list, in this format:\n",
      "Product description: A shoe that fits any foot size\n",
      "Product names: [list of 3 product names]\n",
      "\n",
      "## Example\n",
      "Product description: A refrigerator that dispenses beer\n",
      "Product names: iBarFridge, iFridgeBeer, iDrinkBeerFridge\n",
      "\n",
      "Product description: A watch that can tell accurate time in space\n",
      "Product names: iNaut, iSpace, iTime\n",
      "\n",
      "Product description: A home milkshake maker\n",
      "Product names: iShake, iSmoothie, iShake Mini\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the one, two, three shot prompts\n",
    "prompt_one_shot = prompt_zero_shot + \"\\n\\n## Example\"\n",
    "prompt_one_shot += f\"\\nProduct description: {examples[0]['description']}\\n\"\n",
    "prompt_one_shot += f\"Product names: {examples[0]['names']}\\n\"\n",
    "\n",
    "prompt_two_shot = prompt_one_shot\n",
    "prompt_two_shot += f\"\\nProduct description: {examples[1]['description']}\\n\"\n",
    "prompt_two_shot += f\"Product names: {examples[1]['names']}\\n\"\n",
    "\n",
    "prompt_three_shot = prompt_two_shot\n",
    "prompt_three_shot += f\"\\nProduct description: {examples[2]['description']}\\n\"\n",
    "prompt_three_shot += f\"Product names: {examples[2]['names']}\\n\"\n",
    "\n",
    "# print out the prompts\n",
    "print(\"---\\nZero-shot prompt:\\n---\")\n",
    "print(prompt_zero_shot, \"\\n\")\n",
    "\n",
    "print(\"---\\nOne-shot prompt:\\n---\")\n",
    "print(prompt_one_shot, \"\\n\")\n",
    "\n",
    "print(\"---\\nTwo-shot prompt:\\n---\")\n",
    "print(prompt_two_shot, \"\\n\")\n",
    "\n",
    "print(\"---\\nThree-shot prompt:\\n---\")\n",
    "print(prompt_three_shot, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot accuracy: 21.11%\n",
      "One-shot accuracy: 100.00%\n",
      "Two-shot accuracy: 100.00%\n",
      "Three-shot accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Run the zero shot and few shot prompts 30 times each and count the number of correct responses as a percentage of the total\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply() # to run async in jupyter notebook\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "async_client = AsyncOpenAI()\n",
    "\n",
    "async def run_and_evaluate(prompt, num_runs=30):\n",
    "    \"\"\"\n",
    "    Runs the given prompt multiple times and evaluates the accuracy of the responses asynchronously.\n",
    "\n",
    "    This function sends the provided prompt to the GPT-3.5-turbo model multiple times,\n",
    "    evaluates each response to check if all product names start with 'i',\n",
    "    and calculates the percentage of correct responses.\n",
    "\n",
    "    Args:\n",
    "    prompt (str): The prompt to be sent to the model.\n",
    "    num_runs (int): The number of times to run the prompt. Defaults to 30.\n",
    "\n",
    "    Returns:\n",
    "    float: The percentage of correct responses (where all product names start with 'i').\n",
    "    \"\"\"\n",
    "    async def process_single_run():\n",
    "        response = await async_client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        percentage = eval_names_start_with_i(content)\n",
    "        return percentage\n",
    "\n",
    "    tasks = [process_single_run() for _ in range(num_runs)]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    correct_count = sum(results) / len(results)\n",
    "    return correct_count\n",
    "\n",
    "# ... rest of the code remains the same\n",
    "\n",
    "async def main():\n",
    "    zero_shot_accuracy = await run_and_evaluate(prompt_zero_shot)\n",
    "    print(f\"Zero-shot accuracy: {zero_shot_accuracy:.2f}%\")\n",
    "\n",
    "    one_shot_accuracy = await run_and_evaluate(prompt_one_shot)\n",
    "    print(f\"One-shot accuracy: {one_shot_accuracy:.2f}%\")\n",
    "\n",
    "    two_shot_accuracy = await run_and_evaluate(prompt_two_shot)\n",
    "    print(f\"Two-shot accuracy: {two_shot_accuracy:.2f}%\")\n",
    "\n",
    "    three_shot_accuracy = await run_and_evaluate(prompt_three_shot)\n",
    "    print(f\"Three-shot accuracy: {three_shot_accuracy:.2f}%\")\n",
    "\n",
    "# Run the main function\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
